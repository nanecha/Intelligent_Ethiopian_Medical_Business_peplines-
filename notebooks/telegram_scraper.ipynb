{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wspw64gZiEal"
      },
      "source": [
        "# Task 1 - Data Scraping and Collection (Extract & Load)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "80C47c68iDh8"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from telethon.sync import TelegramClient\n",
        "from telethon.tl.types import MessageMediaPhoto\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iUoGg2Dxim-U"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('telegram_scraper.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C6Xmlgui1e8"
      },
      "outputs": [],
      "source": [
        "async def scrape_telegram_channels(api_id, api_hash, channels, data_lake_path='F:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages'):\n",
        "    \"\"\"\n",
        "    Scrape messages and images from specified Telegram channels and store in a data lake.\n",
        "\n",
        "    Args:\n",
        "        api_id (str): Telegram API ID\n",
        "        api_hash (str): Telegram API Hash\n",
        "        channels (list): List of Telegram channel URLs or usernames (e.g., ['@Chemed123', 't.me/lobelia4cosmetics'])\n",
        "        data_lake_path (str): Base path for data lake storage\n",
        "\n",
        "    Returns:\n",
        "        list: List of paths to saved JSON files\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize Telegram client\n",
        "        client = TelegramClient('session_name', api_id, api_hash)\n",
        "        await client.start()\n",
        "        logger.info(\"Telegram client initialized\")\n",
        "\n",
        "        # Set up data lake directory\n",
        "        DATA_LAKE_PATH = Path(data_lake_path)\n",
        "        DATA_LAKE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        saved_files = []\n",
        "\n",
        "        # Process each channel\n",
        "        for channel_url in channels:\n",
        "            try:\n",
        "                # Normalize channel URL or username\n",
        "                channel_name = channel_url.split('/')[-1] if 't.me' in channel_url else channel_url.lstrip('@')\n",
        "                logger.info(f\"Processing channel: {channel_name}\")\n",
        "\n",
        "                # Resolve channel entity\n",
        "                channel = await client.get_entity(channel_url)\n",
        "\n",
        "                # Get current date for partitioning\n",
        "                current_date = datetime.now().strftime('%Y-%m-%d')\n",
        "                output_dir = DATA_LAKE_PATH / current_date / channel_name\n",
        "                output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                # Scrape messages\n",
        "                messages_data = []\n",
        "                async for message in client.iter_messages(channel, limit=100):  # Adjust limit as needed\n",
        "                    try:\n",
        "                        msg_data = {\n",
        "                            'message_id': message.id,\n",
        "                            'date': message.date.isoformat(),\n",
        "                            'text': message.text or '',\n",
        "                            'sender_id': message.sender_id,\n",
        "                            'views': message.views or 0,\n",
        "                            'forwards': message.forwards or 0,\n",
        "                            'media': None\n",
        "                        }\n",
        "\n",
        "                        # Handle media (photos)\n",
        "                        if isinstance(message.media, MessageMediaPhoto):\n",
        "                            try:\n",
        "                                photo_path = output_dir / f\"photo_{message.id}.jpg\"\n",
        "                                await message.download_media(file=str(photo_path))\n",
        "                                msg_data['media'] = str(photo_path)\n",
        "                                logger.info(f\"Downloaded photo for message {message.id} to {photo_path}\")\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"Error downloading media for message {message.id}: {str(e)}\")\n",
        "\n",
        "                        messages_data.append(msg_data)\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error processing message {message.id} in {channel_name}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "                # Save messages to JSON\n",
        "                if messages_data:\n",
        "                    output_file = output_dir / 'messages.json'\n",
        "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                        json.dump(messages_data, f, ensure_ascii=False, indent=2)\n",
        "                    logger.info(f\"Saved {len(messages_data)} messages to {output_file}\")\n",
        "                    saved_files.append(str(output_file))\n",
        "                else:\n",
        "                    logger.warning(f\"No messages scraped for {channel_name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing channel {channel_name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        await client.disconnect()\n",
        "        logger.info(\"Telegram client disconnected\")\n",
        "        return saved_files\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Fatal error in scrape_telegram_channels: {str(e)}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "jUkrgrMHjNWM",
        "outputId": "53864dde-b042-402e-ff6f-632543d161ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Telegram API credentials (get from https://my.telegram.org)\n",
            "Enter API ID: 29992189\n",
            "Enter API Hash: f234baf39ded2ba05973aba75d9b9f71\n",
            "Please enter your phone (or bot token): +251996665090\n",
            "Please enter the code you received: 57888\n",
            "Signed in successfully as Nanecha Kebede; remember to not break the ToS or you will risk an account ban!\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a3321ac7-d21f-45b1-834f-8b7ba2797b00\", \"data_lake.zip\", 19248103)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import asyncio\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from telethon.sync import TelegramClient\n",
        "from telethon.tl.types import MessageMediaPhoto\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the Telegram scraper in Colab.\n",
        "    Prompts for API credentials and runs the scraping process.\n",
        "    \"\"\"\n",
        "    # Telegram API credentials (replace with your own or prompt user)\n",
        "    print(\"Please provide your Telegram API credentials (get from https://my.telegram.org)\")\n",
        "    api_id = input(\"Enter API ID: \")\n",
        "    api_hash = input(\"Enter API Hash: \")\n",
        "\n",
        "    # Define channels to scrape\n",
        "    channels = [\n",
        "        't.me/Chemed123',\n",
        "        't.me/lobelia4cosmetics',\n",
        "        't.me/tikvahpharma'\n",
        "    ]\n",
        "\n",
        "    # Run scraper\n",
        "    saved_files = asyncio.run(scrape_telegram_channels(api_id, api_hash, channels))\n",
        "\n",
        "    # Zip and download data lake\n",
        "    logger.info(\"Zipping data lake...\")\n",
        "    shutil.make_archive('data_lake', 'zip', 'data/raw/telegram_messages')\n",
        "    logger.info(\"Downloading data lake...\")\n",
        "    files.download('data_lake.zip')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EvfnkeQ1xTW",
        "outputId": "978640c5-acfa-4de7-cc78-bd5b7ba65baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for message files in: data/raw/telegram_messages\n",
            "Found 3 message files.\n",
            "\n",
            "--- Messages from data/raw/telegram_messages/2025-07-22/lobelia4cosmetics/messages.json ---\n",
            "  Message ID: 18694\n",
            "  Date: 2025-07-22T06:24:50+00:00\n",
            "  Text: CETAPHIL BABY LOTION **\n",
            "Price 3800 birr \n",
            "Telegram :-****@Lobeliacosmetics****\n",
            "MsgðŸ‘‰ Lobelia pharmacy ...\n",
            "--------------------\n",
            "  Message ID: 18692\n",
            "  Date: 2025-07-22T06:21:33+00:00\n",
            "  Text: AQUAPHOR BABY WASH **\n",
            "Price 3800 birr \n",
            "Telegram :-****@Lobeliacosmetics****\n",
            "MsgðŸ‘‰ Lobelia pharmacy an...\n",
            "--------------------\n",
            "  Message ID: 18691\n",
            "  Date: 2025-07-22T06:20:46+00:00\n",
            "  Text: **ENFAMIL NEUROPRO CARE\n",
            "Price 6500 birr \n",
            "Telegram :-****@Lobeliacosmetics****\n",
            "MsgðŸ‘‰ Lobelia pharmacy ...\n",
            "--------------------\n",
            "  Message ID: 18690\n",
            "  Date: 2025-07-21T15:53:24+00:00\n",
            "  Text: ENFAMIL A+ 765GM**\n",
            "Price 6500 birr \n",
            "Telegram :-****@Lobeliacosmetics****\n",
            "MsgðŸ‘‰ Lobelia pharmacy and c...\n",
            "--------------------\n",
            "  Message ID: 18689\n",
            "  Date: 2025-07-21T13:33:00+00:00\n",
            "  Text: **Mini Drop **Vitamin D3**\n",
            "Price 3000 birr \n",
            "Telegram :-****@Lobeliacosmetics****\n",
            "MsgðŸ‘‰ Lobelia pharma...\n",
            "--------------------\n",
            "  ... and 95 more messages.\n",
            "\n",
            "--- Messages from data/raw/telegram_messages/2025-07-22/tikvahpharma/messages.json ---\n",
            "  Message ID: 173326\n",
            "  Date: 2025-07-22T09:00:50+00:00\n",
            "  Text: **#Circumcision_Skill_Training**** (Adult & Neonates with Ring ) Â á‰ á‰€áˆˆá‰ á‰µáŠ“ á‹«áˆˆá‰€áˆˆá‰ á‰µ âž¥Â  áŠ¨ áˆáˆáˆŒ 20 áŒ€áˆáˆ® á‹­áˆ°áŒ£áˆ...\n",
            "--------------------\n",
            "  Message ID: 173320\n",
            "  Date: 2025-07-22T08:14:56+00:00\n",
            "  Text: **ðŸ”¹ COMEN CH8300**\n",
            "âœ… 3-Part Differentiation\n",
            "âœ… 21 Parameters\n",
            "âœ… 70 Tests/hour\n",
            "ðŸ’¡ Best for clinics start...\n",
            "--------------------\n",
            "  Message ID: 173319\n",
            "  Date: 2025-07-22T08:03:50+00:00\n",
            "  Text: NURSE\n",
            "\n",
            "experience 0 year and above\n",
            "\n",
            "Qualification:Â degree and diplom\n",
            "\n",
            "Â Â Â Â Â Â Â  Work area\n",
            "\n",
            "\n",
            "(1) sar be...\n",
            "--------------------\n",
            "  Message ID: 173316\n",
            "  Date: 2025-07-22T07:34:09+00:00\n",
            "  Text: **Tikvah Sales\n",
            "(Pharma Import)\n",
            "\n",
            "****ðŸ†•****Update\n",
            "\n",
            "#â–¯Miconazole cr.\n",
            "#â–¯Amilodipin 5mg\n",
            "#â–¯Sildanafil 50mg...\n",
            "--------------------\n",
            "  Message ID: 173313\n",
            "  Date: 2025-07-22T07:15:23+00:00\n",
            "  Text: ðŸ“¢ **VivaMed Pharma â€“ Weekly Product Availability Update**\n",
            "**Date: July 22, 2025**\n",
            "\n",
            "Wishing you a str...\n",
            "--------------------\n",
            "  ... and 95 more messages.\n",
            "\n",
            "--- Messages from data/raw/telegram_messages/2025-07-22/Chemed123/messages.json ---\n",
            "  Message ID: 97\n",
            "  Date: 2023-02-10T12:23:06+00:00\n",
            "  Text: âš ï¸**Notice!\n",
            "**Dear esteemed customers,\n",
            "Due to four-day motorbike movement restrictions, we have limi...\n",
            "--------------------\n",
            "  Message ID: 96\n",
            "  Date: 2023-02-02T08:58:52+00:00\n",
            "  Text: Mela-One á‰ á‹áˆµáŒ¡ áˆ†áˆ­áˆžáŠ• á‹«áˆˆá‹ á‹µáŠ•áŒˆá‰°áŠ› á‹ˆáˆŠá‹µ áˆ˜á‰†áŒ£áŒ áˆ­á‹« áˆ²áˆ†áŠ• á‹«áˆˆáˆ˜áŠ¨áˆ‹áŠ¨á‹« á‹¨á‰°á‹°áˆ¨áŒˆ á‹¨áŒá‰¥áˆ¨áˆµáŒ‹ áŒáŠ•áŠ™áŠá‰µ áˆ²áŠ–áˆ­ á‰ 72 áˆ°á‹“á‰³á‰µ á‹ˆáˆµáŒ¥ áˆ˜á‹ˆáˆ°á‹µ á‹­áŠ–áˆ­á‰ á‰³áˆá¢...\n",
            "--------------------\n",
            "  Message ID: 95\n",
            "  Date: 2023-02-01T08:59:37+00:00\n",
            "  Text: **áŠ á‹šá‰µáˆ®áˆ›á‹­áˆ²áŠ•** á‰ áˆƒáŠªáˆ áˆ˜á‹µáˆƒáŠ’á‰µ áˆ›á‹˜á‹£ áŠ¨áˆšá‰³á‹˜á‹™ áŠ áŠ•á‰²á‰£á‹®á‰²áŠ®á‰½ áŠ áŠ•á‹± áˆ²áˆ†áŠ• á‰ áˆ­áŠ¨á‰µ á‹«áˆ‰ á‰£áŠ­á‰´áˆ­á‹«á‹Žá‰½áŠ• á‹­áŒˆáˆ‹áˆá¢\n",
            "\n",
            "á‰ á‰€áŠ• áŠ áŠ•á‹´ áˆˆ3 á‰€áŠ“á‰µ áˆáŒá‰¥ áŠ¨áˆ˜á‰¥áˆ‹á‰³á‰½...\n",
            "--------------------\n",
            "  Message ID: 94\n",
            "  Date: 2023-01-31T09:19:53+00:00\n",
            "  Text: **Che-Med Trivia #3\n",
            "\n",
            "**áˆáŒá‰¥áŠ“ áˆ˜áŒ áŒ¦á‰½ áŠ áŠ•á‹³áŠ•á‹µ áˆ˜á‹µáˆƒáŠ’á‰¶á‰½ á‰ á‹°áŠ•á‰¥ áŠ¥áŠ•á‹³á‹­áˆ°áˆ© áˆŠá‹«á‹°áˆ­áŒ‰ á‹­á‰½áˆ‹áˆ‰á¢ á‰ á‹šáˆ… áˆáŠ”á‰³ áŠ¥áŠá‹šáˆ…áŠ• áˆ˜á‹µáˆƒáŠ’á‰¶á‰½ áˆáŒá‰¥ áŠ¨á‹ˆáˆ°á‹µáŠ•...\n",
            "--------------------\n",
            "  Message ID: 93\n",
            "  Date: 2023-01-30T09:45:25+00:00\n",
            "  Text: **Che-Med Trivia #2\n",
            "\n",
            "**áŠ¥áŠ•á‹° Ciprofloxacin, Doxycycline, Levothyroxine, Iron supplement á‹«áˆ‰ áˆ˜á‹µáˆƒáŠ’á‰¶á‰½áŠ• áŠ¨á‹ˆá‰°...\n",
            "--------------------\n",
            "  ... and 71 more messages.\n"
          ]
        }
      ],
      "source": [
        "# prompt: how can i print message from data lake?\n",
        "\n",
        "def print_messages_from_data_lake(data_lake_path='F:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages'):\n",
        "    \"\"\"\n",
        "    Reads and prints a sample of messages from the data lake.\n",
        "\n",
        "    Args:\n",
        "        data_lake_path (str): Base path for data lake storage\n",
        "    \"\"\"\n",
        "    DATA_LAKE_PATH = Path(data_lake_path)\n",
        "\n",
        "    if not DATA_LAKE_PATH.exists():\n",
        "        print(f\"Data lake path not found: {data_lake_path}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Looking for message files in: {data_lake_path}\")\n",
        "    # Find all messages.json files within the data lake structure\n",
        "    message_files = list(DATA_LAKE_PATH.rglob('messages.json'))\n",
        "\n",
        "    if not message_files:\n",
        "        print(\"No 'messages.json' files found in the data lake.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(message_files)} message files.\")\n",
        "\n",
        "    for msg_file in message_files:\n",
        "        try:\n",
        "            with open(msg_file, 'r', encoding='utf-8') as f:\n",
        "                messages = json.load(f)\n",
        "                print(f\"\\n--- Messages from {msg_file} ---\")\n",
        "                # Print a sample of messages\n",
        "                for i, msg in enumerate(messages[:5]): # Print first 5 messages\n",
        "                    print(f\"  Message ID: {msg['message_id']}\")\n",
        "                    print(f\"  Date: {msg['date']}\")\n",
        "                    print(f\"  Text: {msg['text'][:100]}...\") # Print first 100 chars of text\n",
        "                    print(\"-\" * 20)\n",
        "                if len(messages) > 5:\n",
        "                    print(f\"  ... and {len(messages) - 5} more messages.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {msg_file}: {str(e)}\")\n",
        "\n",
        "# Example of how to call the function after the scraping is done\n",
        "# This should be called AFTER the main() function has finished and created the data lake files.\n",
        "# main() # Uncomment this line to run the scraper first\n",
        "print_messages_from_data_lake()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Q35joz31We"
      },
      "outputs": [],
      "source": [
        "# prompt: to downloade the message from /content/data/raw/telegram_messages of coolab to local machine?\n",
        "\n",
        "# The provided code already includes a zip and download step at the end of the main() function.\n",
        "# This code snippet extracts that part to allow running it independently after the scraper\n",
        "# has finished creating the 'data/raw/telegram_messages' directory.\n",
        "\n",
        "logger.info(\"Zipping data lake...\")\n",
        "# Ensure the data_lake.zip file is created at the top level\n",
        "shutil.make_archive('data_lake', 'zip', 'data/raw/telegram_messages')\n",
        "logger.info(\"Downloading data lake...\")\n",
        "files.download('data_lake.zip')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
