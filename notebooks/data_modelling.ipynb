{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2 -  Data Modeling and Transformation (Transform)\n",
        "**Under this Task the following activities are accomplished\n",
        "- the scraped JSON files from my data lake was loaded into a raw schema in my PostgreSQL database.\n",
        "- Installing  dbt and its PostgreSQL adapter and setting  up a DBT project.\n",
        "- by Initialize a DBT project connection  to  PostgreSQL database.\n",
        "- Develop dbt Models in Layers:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XJdG1744Ca3_"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "import logging\n",
        "import sys \n",
        "import os\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GBlKOkZcCm6c"
      },
      "outputs": [],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('load_json_to_postgres.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function Definition:\n",
        "It defines the function load_json_to_postgres with two arguments:\n",
        "data_lake_path: The path to the directory where the JSON files are located (default is 'data/raw/telegram_messages').\n",
        "db_url: The connection URL for the PostgreSQL database (default is 'postgresql://user:password@localhost:5432/kara_db').\n",
        "Database Connection and Schema Creation:\n",
        "It uses the sqlalchemy library to create a connection engine to the PostgreSQL database using the provided db_url.\n",
        "It then connects to the database and executes SQL commands to:\n",
        "Create a schema named raw if it doesn't already exist.\n",
        "Create a table named telegram_messages within the raw schema if it doesn't exist. This table is designed to store the data from the JSON files with specific columns like message_id, channel_name, date, text, etc.\n",
        "JSON File Collection:\n",
        "It uses the pathlib module to find all JSON files (.json) within the specified data_lake_path and its subdirectories.\n",
        "If no JSON files are found, it logs a warning and returns 0, indicating that no records were loaded.\n",
        "Iterating and Loading JSON Files:\n",
        "It iterates through each found JSON file.\n",
        "For each file:\n",
        "It extracts the channel_name and date_str from the file's path based on a presumed directory structure (e.g., data/raw/telegram_messages/YYYY-MM-DD/channel_name/file.json).\n",
        "It opens and loads the JSON data from the file into a Python list of dictionaries.\n",
        "It converts this list of dictionaries into a pandas DataFrame.\n",
        "It adds a channel_name column to the DataFrame with the extracted channel name.\n",
        "It adds a load_date column with the current timestamp.\n",
        "It uses the df.to_sql() method to append the DataFrame's data to the telegram_messages table in the raw schema of the PostgreSQL database.\n",
        "Error Handling and Logging:\n",
        "It includes try...except blocks to handle potential errors during file processing or database operations.\n",
        "It uses the logging module to log information about the process (e.g., database connection, number of records loaded from each file) and any errors that occur.\n",
        "Return Value:\n",
        "The function returns the total number of records successfully loaded from all the JSON fil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw table created successfully.\n",
            "JSON data loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import psycopg2\n",
        "from psycopg2.extras import Json\n",
        "\n",
        "# Database connection parameters\n",
        "db_params = {\n",
        "    'dbname': 'kara_medical_db',\n",
        "    'user': 'postgres',\n",
        "    'password': 'n5090',\n",
        "    'host': 'localhost',\n",
        "    'port': '5432'\n",
        "}\n",
        "\n",
        "# Data lake directory\n",
        "data_lake_path = 'F:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages'\n",
        "\n",
        "def create_raw_table():\n",
        "    try:\n",
        "        conn = psycopg2.connect(**db_params)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"\"\"\n",
        "            CREATE SCHEMA IF NOT EXISTS raw;\n",
        "            DROP TABLE IF EXISTS raw.telegram_messages CASCADE;\n",
        "            CREATE TABLE raw.telegram_messages (\n",
        "                id SERIAL PRIMARY KEY,\n",
        "                json_data JSONB NOT NULL,\n",
        "                file_name VARCHAR(255),\n",
        "                channel_name VARCHAR(255),\n",
        "                loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "            );\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "        print(\"Raw table created successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating raw table: {e}\")\n",
        "    finally:\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "\n",
        "def load_json_files():\n",
        "    try:\n",
        "        conn = psycopg2.connect(**db_params)\n",
        "        cur = conn.cursor()\n",
        "        json_files = [f for f in os.listdir(data_lake_path) if f.endswith('.json')]\n",
        "        if len(json_files) != 3:\n",
        "            print(f\"Warning: Found {len(json_files)} JSON files, expected 3: {json_files}\")\n",
        "        for file in json_files:\n",
        "            file_path = os.path.join(data_lake_path, file)\n",
        "            # Derive channel_name from file name (e.g., 'channel1' from 'channel1.json')\n",
        "            channel_name = os.path.splitext(file)[0]\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    json_data = json.load(f)\n",
        "                    # Handle list of messages\n",
        "                    if isinstance(json_data, list):\n",
        "                        for item in json_data:\n",
        "                            cur.execute(\n",
        "                                \"INSERT INTO raw.telegram_messages (json_data, file_name, channel_name) VALUES (%s, %s, %s)\",\n",
        "                                (Json(item), file, channel_name)\n",
        "                            )\n",
        "                    else:\n",
        "                        cur.execute(\n",
        "                            \"INSERT INTO raw.telegram_messages (json_data, file_name, channel_name) VALUES (%s, %s, %s)\",\n",
        "                            (Json(json_data), file, channel_name)\n",
        "                        )\n",
        "                except json.JSONDecodeError as je:\n",
        "                    print(f\"Error decoding JSON in {file_path}: {je}\")\n",
        "        conn.commit()\n",
        "        print(\"JSON data loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON data: {e}\")\n",
        "    finally:\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_raw_table()\n",
        "    load_json_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "psql -U postgres -d kara_medical_db -c \"SELECT 1;\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud8RAdeHCq8z"
      },
      "outputs": [],
      "source": [
        "def load_json_to_postgres(data_lake_path='F:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages',\n",
        "                         db_url='postgresql://postgres:n5090@localhost:5432/kara_db'):\n",
        "    \"\"\"\n",
        "    Load JSON files from the data lake into a PostgreSQL raw schema.\n",
        "\n",
        "    Args:\n",
        "        data_lake_path (str): Path to the data lake directory\n",
        "        db_url (str): PostgreSQL connection URL\n",
        "\n",
        "    Returns:\n",
        "        int: Number of records loaded\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize database connection\n",
        "        engine = create_engine(db_url)\n",
        "        logger.info(\"Connected to PostgreSQL database\")\n",
        "\n",
        "        # Create raw schema if not exists\n",
        "        with engine.connect() as conn:\n",
        "            conn.execute(\"CREATE SCHEMA IF NOT EXISTS raw\")\n",
        "            conn.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS raw.telegram_messages (\n",
        "                    message_id BIGINT,\n",
        "                    channel_name TEXT,\n",
        "                    date TIMESTAMP,\n",
        "                    text TEXT,\n",
        "                    sender_id BIGINT,\n",
        "                    views INTEGER,\n",
        "                    forwards INTEGER,\n",
        "                    media_path TEXT,\n",
        "                    load_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "                )\n",
        "            \"\"\")\n",
        "            conn.commit()\n",
        "\n",
        "        # Collect all JSON files\n",
        "        json_files = list(Path(data_lake_path).glob('**/*.json'))\n",
        "        if not json_files:\n",
        "            logger.warning(\"No JSON files found in data lake\")\n",
        "            return 0\n",
        "\n",
        "        total_records = 0\n",
        "        for json_file in json_files:\n",
        "            try:\n",
        "                # Extract channel name and date from path\n",
        "                channel_name = json_file.parent.name\n",
        "                date_str = json_file.parent.parent.name  # YYYY-MM-DD\n",
        "\n",
        "                # Load JSON data\n",
        "                with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                    messages = json.load(f)\n",
        "\n",
        "                # Convert to DataFrame\n",
        "                df = pd.DataFrame(messages)\n",
        "                df['channel_name'] = channel_name\n",
        "                df['load_date'] = pd.Timestamp.now()\n",
        "\n",
        "                # Write to PostgreSQL\n",
        "                df.to_sql('telegram_messages', engine, schema='raw', if_exists='append', index=False)\n",
        "                logger.info(f\"Loaded {len(df)} records from {json_file}\")\n",
        "                total_records += len(df)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing {json_file}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        logger.info(f\"Total records loaded: {total_records}\")\n",
        "        return total_records\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Fatal error in load_json_to_postgres: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "siPq8MwUEK2b",
        "outputId": "819d8b87-d998-42b6-f20f-4e4a465cd102"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-19 19:56:38,139 - INFO - Connected to PostgreSQL database\n",
            "2025-08-19 19:56:38,758 - ERROR - Fatal error in load_json_to_postgres: Not an executable object: 'CREATE SCHEMA IF NOT EXISTS raw'\n"
          ]
        },
        {
          "ename": "ObjectNotExecutableError",
          "evalue": "Not an executable object: 'CREATE SCHEMA IF NOT EXISTS raw'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\Intelligent_Ethiopian_Medical_Business_peplines-\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1411\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     meth = \u001b[43mstatement\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_on_connection\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute '_execute_on_connection'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mObjectNotExecutableError\u001b[39m                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m     records_loaded = load_json_to_postgres(data_lake_path=\u001b[33m'\u001b[39m\u001b[33mF:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages\u001b[39m\u001b[33m'\u001b[39m, db_url=db_url)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m db_url = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter PostgreSQL connection URL (e.g., postgresql://user:password@localhost:5432/kara_medical_db): \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m records_loaded = \u001b[43mload_json_to_postgres\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lake_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mF:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_url\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mload_json_to_postgres\u001b[39m\u001b[34m(data_lake_path, db_url)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Create raw schema if not exists\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m engine.connect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCREATE SCHEMA IF NOT EXISTS raw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     conn.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33m        CREATE TABLE IF NOT EXISTS raw.telegram_messages (\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m            message_id BIGINT,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33m        )\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     34\u001b[39m     conn.commit()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\Intelligent_Ethiopian_Medical_Business_peplines-\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1413\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1411\u001b[39m     meth = statement._execute_on_connection\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m-> \u001b[39m\u001b[32m1413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[32m   1416\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1417\u001b[39m         distilled_parameters,\n\u001b[32m   1418\u001b[39m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[32m   1419\u001b[39m     )\n",
            "\u001b[31mObjectNotExecutableError\u001b[39m: Not an executable object: 'CREATE SCHEMA IF NOT EXISTS raw'"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the JSON loader in Colab.\n",
        "    \"\"\"\n",
        "    # Replace with your PostgreSQL credentials\n",
        "    db_url = input(\"Enter PostgreSQL connection URL (e.g., postgresql://user:password@localhost:5432/): \")\n",
        "kara_medical_db\n",
        "    # Load data\n",
        "    records_loaded = load_json_to_postgres(data_lake_path='F:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages', db_url=db_url)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import psycopg2\n",
        "\n",
        "# PostgreSQL connection\n",
        "conn = psycopg2.connect(\n",
        "    dbname=\"kara_medical_db\",\n",
        "    user=\"postgres\",\n",
        "    password=\"n5090\",\n",
        "    host=\"localhost\",\n",
        "    port=\"5432\"\n",
        ")\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Create raw schema if not exists\n",
        "cur.execute(\"CREATE SCHEMA IF NOT EXISTS raw;\")\n",
        "\n",
        "# Drop old table (optional, good for dev to avoid missing columns issue)\n",
        "cur.execute(\"DROP TABLE IF EXISTS raw.telegram_messages;\")\n",
        "\n",
        "# Create raw table with correct schema\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE raw.telegram_messages (\n",
        "    message_id BIGINT,\n",
        "    sender_id BIGINT,\n",
        "    message_text TEXT,\n",
        "    posted_at TIMESTAMPTZ,\n",
        "    views INT,\n",
        "    forwards INT,\n",
        "    media_url TEXT,\n",
        "    raw_json JSONB,\n",
        "    PRIMARY KEY (sender_id, message_id)  -- composite key for ON CONFLICT\n",
        ");\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "\n",
        "# Load JSON files\n",
        "data_dir = \"F:/Intelligent_Ethiopian_Medical_Business_peplines-/data/raw/telegram_messages\"\n",
        "for file in os.listdir(data_dir):\n",
        "    if file.endswith(\".json\"):\n",
        "        with open(os.path.join(data_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
        "            messages = json.load(f)\n",
        "            for msg in messages:\n",
        "                cur.execute(\"\"\"\n",
        "                    INSERT INTO raw.telegram_messages\n",
        "                    (message_id, sender_id, message_text, posted_at, views, forwards, media_url, raw_json)\n",
        "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
        "                    ON CONFLICT (sender_id, message_id) DO NOTHING;\n",
        "                \"\"\", (\n",
        "                    msg.get(\"message_id\"),\n",
        "                    msg.get(\"sender_id\"),\n",
        "                    msg.get(\"text\"),\n",
        "                    msg.get(\"date\"),\n",
        "                    msg.get(\"views\"),\n",
        "                    msg.get(\"forwards\"),\n",
        "                    msg.get(\"media\"),\n",
        "                    json.dumps(msg)\n",
        "                ))\n",
        "\n",
        "conn.commit()\n",
        "cur.close()\n",
        "conn.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total messages: 276\n"
          ]
        }
      ],
      "source": [
        "\n",
        "conn = psycopg2.connect(\n",
        "    dbname=\"kara_medical_db\",\n",
        "    user=\"postgres\",\n",
        "    password=\"n5090\",\n",
        "    host=\"localhost\",\n",
        "    port=\"5432\"\n",
        ")\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute(\"SELECT COUNT(*) FROM raw.telegram_messages;\")\n",
        "print(\"Total messages:\", cur.fetchone()[0])\n",
        "\n",
        "cur.close()\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
